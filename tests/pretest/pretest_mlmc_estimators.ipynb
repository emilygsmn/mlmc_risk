{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5997341d",
   "metadata": {},
   "source": [
    "## MLMC Estimator Pretest - Proof of Concept\n",
    "\n",
    "This notebook investigates the behaviour of different multilevel Monta Carlo extensions of the Harrell-Davis quantile estimator, specifically regarding their accuracy and variance.\n",
    "\n",
    "To understand the characteristics of the proposed estimators, the QOI is chosen as a quantile of a well-known distribution - the normal distribution $N(\\mu, \\sigma^2)$.\n",
    "\n",
    "### 1. Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c05f514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of interest: \n",
    "mu = -10\n",
    "sd = 200\n",
    "\n",
    "# Quantile of interest:\n",
    "p = 0.005\n",
    "\n",
    "# Model valuation costs:\n",
    "c_f = 1\n",
    "c_c = c_f / 100\n",
    "\n",
    "# Number of samples:\n",
    "n_f = 10\n",
    "n_c = 50000\n",
    "n_std_mc = int((n_f * c_f + n_c * c_c) / c_f)\n",
    "\n",
    "# Number of bootstrap samples:\n",
    "n_bootstrap = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5aab69",
   "metadata": {},
   "source": [
    "### 2. Define the sampling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "390181a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def SampleLevel1(mu, sd, n_f):\n",
    "    fineModelSamples = np.random.normal(mu, sd, n_f)\n",
    "    eps = 50 * np.random.normal(0, 0.6, n_f)\n",
    "    coarseModelSamples_lvl1 = fineModelSamples + eps\n",
    "    return fineModelSamples, coarseModelSamples_lvl1, eps\n",
    "\n",
    "def SampleLevel2(mu, sd, n_c):\n",
    "    eps = 50 * np.random.normal(0, 0.6, n_c)\n",
    "    coarseModelSamples_50000 = np.random.normal(mu, sd, n_c) + eps\n",
    "    return coarseModelSamples_50000, eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8ce6f",
   "metadata": {},
   "source": [
    "### 3. Define Harrell-Davis weighting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3b3105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as scp\n",
    "\n",
    "def HarrellDavisWeighting(p, xSorted):\n",
    "    n = xSorted.size\n",
    "    hd = np.empty((2), np.float64)\n",
    "    if n < 2:\n",
    "        hd.flat = np.nan\n",
    "        return hd[0]\n",
    "    v = np.arange(n+1) / float(n)\n",
    "    betacdf = scp.stats.distributions.beta.cdf\n",
    "    _w = betacdf(v, (n+1)*p, (n+1)*(1-p))\n",
    "    w = _w[1:] - _w[:-1]\n",
    "    hd_mean = np.dot(w, xSorted)\n",
    "    hd[0] = hd_mean\n",
    "    hd[1] = np.dot(w, (xSorted-hd_mean)**2)\n",
    "    return hd[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a115419",
   "metadata": {},
   "source": [
    "### 4. Define Quantile Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94877ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, mstats\n",
    "import pandas as pd\n",
    "\n",
    "def CalcQuantileEstimates(p, mu, sd, fineSamples, coarseSamples_lvl1, coarseSamples_lvl2, eps2, numStdMCSamples):\n",
    "    # Compute HD estimators\n",
    "    hdEstimatorFineModel = mstats.hdquantiles(data=fineSamples, prob=(p), var=False).item()\n",
    "    hdEstimatorCoarseModel_lvl1 = mstats.hdquantiles(data=coarseSamples_lvl1, prob=(p), var=False).item()\n",
    "    hdEstimatorCoarseModel_lvl2 = mstats.hdquantiles(data=coarseSamples_lvl2, prob=(p), var=False).item()\n",
    "\n",
    "    # Compute order statistics\n",
    "    fineModelOrderStats = np.sort(fineSamples)\n",
    "    coarseModelOrderStats_lvl1 = np.sort(coarseSamples_lvl1)\n",
    "    coarseModelOrderStats_lvl2 = np.sort(coarseSamples_lvl2)\n",
    "\n",
    "    # MLMC estimators\n",
    "    #mlmcEstimator = hdEstimatorFineModel - hdEstimatorCoarseModel_lvl1 + hdEstimatorCoarseModel_lvl2\n",
    "    mlmcEstimator = (HarrellDavisWeighting(p,fineModelOrderStats)\n",
    "                     - HarrellDavisWeighting(p,coarseModelOrderStats_lvl1)\n",
    "                     + HarrellDavisWeighting(p, coarseModelOrderStats_lvl2)\n",
    "    )\n",
    "\n",
    "    diffsOfOrderStats = np.sort(fineSamples) - np.sort(coarseSamples_lvl1)\n",
    "    #mlmcEstimatorComb = (mstats.hdquantiles(data=diffs, prob=(p), var=False).item()\n",
    "    #                     + mstats.hdquantiles(data=coarseSamples_lvl2, prob=(p), var=False).item()\n",
    "    #)\n",
    "    mlmcEstimatorComb = (HarrellDavisWeighting(p, diffsOfOrderStats)\n",
    "                         + mstats.hdquantiles(data=coarseSamples_lvl2,\n",
    "                                              prob=(p),\n",
    "                                              var=False).item()\n",
    "    )\n",
    "\n",
    "    diffs = fineSamples - coarseSamples_lvl1\n",
    "    orderStatsOfDiffs = np.sort(diffs)\n",
    "    mlmcEstimatorApprox = (HarrellDavisWeighting(p, orderStatsOfDiffs)\n",
    "                           + mstats.hdquantiles(data=coarseSamples_lvl2, prob=(p), var=False).item()\n",
    "    )\n",
    "\n",
    "    # Standard MC estimator\n",
    "    fineModelSamples_stdMC = coarseSamples_lvl2[0:numStdMCSamples-1] - eps2[0:numStdMCSamples-1]\n",
    "    hdEstimatorStandardMC = mstats.hdquantiles(data=fineModelSamples_stdMC,\n",
    "                                               prob=(p),\n",
    "                                               var=False).item()\n",
    "\n",
    "    # Actual quantile\n",
    "    actualQuantile = norm.ppf(p, loc=mu, scale=sd)\n",
    "\n",
    "    # Combine into a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Value\": [\n",
    "            hdEstimatorFineModel,\n",
    "            hdEstimatorCoarseModel_lvl1,\n",
    "            hdEstimatorCoarseModel_lvl2,\n",
    "            mlmcEstimator,\n",
    "            mlmcEstimatorComb,\n",
    "            mlmcEstimatorApprox,\n",
    "            hdEstimatorStandardMC,\n",
    "            actualQuantile\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857c241",
   "metadata": {},
   "source": [
    "### 5. Apply bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7a0195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    f\"Fine Model HD, {n_f} samples\",\n",
    "    f\"Coarse Model HD, {n_f} samples\",\n",
    "    f\"Coarse Model HD, {n_c} samples\",\n",
    "    \"MLMC (separate terms)\",\n",
    "    \"MLMC (diff. of order stats)\",\n",
    "    \"MLMC (order stats of diff.)\",\n",
    "    f\"Standard MC-HD, {n_std_mc} samples\",\n",
    "    \"Actual Quantile\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({\"Estimator\": estimators})\n",
    "\n",
    "cols = []\n",
    "\n",
    "for i in range(1, n_bootstrap + 1):\n",
    "\n",
    "    fineModelSamples, coarseModelSamples_lvl1, eps1 = SampleLevel1(mu, sd, n_f)\n",
    "    coarseModelSamples_lvl2, eps2 = SampleLevel2(mu, sd, n_c)\n",
    "\n",
    "    col = CalcQuantileEstimates(\n",
    "        p, mu, sd,\n",
    "        fineModelSamples,\n",
    "        coarseModelSamples_lvl1,\n",
    "        coarseModelSamples_lvl2,\n",
    "        eps2,\n",
    "        n_std_mc\n",
    "    )[\"Value\"]\n",
    "\n",
    "    col.name = f\"Run_{i}\"\n",
    "    cols.append(col)\n",
    "\n",
    "new_cols = pd.concat(cols, axis=1)\n",
    "df = pd.concat([df, new_cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3b83a",
   "metadata": {},
   "source": [
    "### 6. Compute bootstrapped statistics for the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f164dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Estimator     Mean   AbsDev     StdDev       RMSE\n",
      "0       Fine Model HD, 10 samples -318.357  206.809  1.177e+02  2.379e+02\n",
      "1     Coarse Model HD, 10 samples -323.942  201.224  1.171e+02  2.328e+02\n",
      "2  Coarse Model HD, 50000 samples -530.899    5.733  4.602e+00  7.350e+00\n",
      "3           MLMC (separate terms) -525.313    0.148  2.903e+01  2.902e+01\n",
      "4     MLMC (diff. of order stats) -525.313    0.148  2.903e+01  2.902e+01\n",
      "5     MLMC (order stats of diff.) -576.602   51.436  1.798e+01  5.448e+01\n",
      "6     Standard MC-HD, 510 samples -535.988   10.822  3.884e+01  4.030e+01\n",
      "7                 Actual Quantile -525.166    0.000  2.275e-13  8.640e-12\n"
     ]
    }
   ],
   "source": [
    "# Compute average across all Run columns\n",
    "run_cols = [f\"Run_{i}\" for i in range(1, n_bootstrap+1)]\n",
    "df[\"Mean\"] = df[run_cols].mean(axis=1)\n",
    "\n",
    "# Extract the Actual Quantile value from the DataFrame\n",
    "actual_value = df.loc[df[\"Estimator\"] == \"Actual Quantile\", \"Mean\"].values[0]\n",
    "\n",
    "# Compute the deviation of the mean from the actual quantile\n",
    "df[\"AbsDev\"] = abs(df[\"Mean\"] - actual_value)\n",
    "\n",
    "# Compute standard deviation across all Run columns\n",
    "df[\"StdDev\"] = df[run_cols].std(axis=1)\n",
    "\n",
    "# Identify all Run columns\n",
    "run_cols = [col for col in df.columns if col.startswith(\"Run_\")]\n",
    "\n",
    "# Compute RMSE (RMS deviation from Actual Quantile)\n",
    "df[\"RMSE\"] = ((df[run_cols] - actual_value) ** 2).mean(axis=1) ** 0.5\n",
    "\n",
    "# Show relevant columns\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "print(df[[\"Estimator\", \"Mean\", \"AbsDev\", \"StdDev\", \"RMSE\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b03c59",
   "metadata": {},
   "source": [
    "### Notations\n",
    "\n",
    "- \"MLMC (separate terms)\" refers to the estimator $\\sum_{i=1}^{n_{\\text{f}}}{W_{i}^{n_{\\text{f}}}X_{(i)}^{\\text{f}}} - \\sum_{i=1}^{n_{\\text{f}}}{W_{i}^{n_{\\text{f}}}X_{(i)}^{\\text{c}}} + \\sum_{i=1}^{n_{\\text{c}}}{W_{i}^{n_{\\text{c}}}X_{(i)}^{\\text{c}}}$\n",
    "- \"MLMC (diff. of order stats)\" refers to the estimator $\\sum_{i=1}^{n_{\\text{f}}}{W_{i}^{n_{\\text{f}}}(X_{(i)}^{\\text{f}} - X_{(i)}^{\\text{c}})} + \\sum_{i=1}^{n_{\\text{c}}}{W_{i}^{n_{\\text{c}}}X_{(i)}^{\\text{c}}}$\n",
    "- \"MLMC (order stats of diff.)\" refers to the estimator $\\sum_{i=1}^{n_{\\text{f}}}{W_{i}^{n_{\\text{f}}}(X^{\\text{f}} - X^{\\text{c}})_{(i)}} + \\sum_{i=1}^{n_{\\text{c}}}{W_{i}^{n_{\\text{c}}}X_{(i)}^{\\text{c}}}$\n",
    "\n",
    "### Observations\n",
    "\n",
    "- Since the Harrell-Davis weights do not depend on the distribution but only on $p$ and $n$, \"MLMC (separate terms)\" and \"MLMC (diff. of order stats)\" yield the same result.\n",
    "- If the difference between the costs $c_{\\text{f}}$ and $c_{\\text{c}}$ is large, \"MLMC (diff. of order stats)\" can yield significantly better results compared to standard HD Monte Carlo.\n",
    "- For $c_{\\text{c}} = \\frac{c_{\\text{f}}}{20}$, \"MLMC (diff. of order stats)\" and standard HD Monte Carlo yield similar results.\n",
    "- If monotonicity between the fina and coarse model is introduced (i.e. the $\\epsilon$ added to the fine model is always non-negative), the results of all MLMC estimators improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
