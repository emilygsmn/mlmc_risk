{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5997341d",
   "metadata": {},
   "source": [
    "## MLMC Estimator Pretest - Proof of Concept\n",
    "\n",
    "This notebook investigates the behaviour of different multilevel Monta Carlo extensions of the Harrell-Davis quantile estimator, specifically regarding their accuracy and variance.\n",
    "\n",
    "To understand the characteristics of the proposed estimators, the QOI is chosen as a quantile of a well-known distribution - the normal distribution $N(\\mu, \\sigma^2)$.\n",
    "\n",
    "### 1. Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c05f514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of interest: \n",
    "mu = -10\n",
    "sd = 200\n",
    "\n",
    "# Quantile of interest:\n",
    "p = 0.005\n",
    "\n",
    "# Model valuation costs:\n",
    "c_f = 1\n",
    "c_c = c_f / 200\n",
    "\n",
    "# Number of samples:\n",
    "n_f = 50\n",
    "n_c = 50000\n",
    "n_std_mc = int((n_f * (c_f + c_c) + n_c * c_c) / c_f)\n",
    "\n",
    "# Number of bootstrap samples:\n",
    "n_bootstrap = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5aab69",
   "metadata": {},
   "source": [
    "### 2. Define the sampling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "390181a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def SampleLevel1(mu, sd, n_f):\n",
    "    fineModelSamples = np.random.normal(mu, sd, n_f)\n",
    "    eps = 50 * np.random.normal(0, 0.6, n_f)\n",
    "    coarseModelSamples_lvl1 = fineModelSamples + eps\n",
    "    return fineModelSamples, coarseModelSamples_lvl1, eps\n",
    "\n",
    "def SampleLevel2(mu, sd, n_c):\n",
    "    eps = 50 * np.random.normal(0, 0.6, n_c)\n",
    "    coarseModelSamples_50000 = np.random.normal(mu, sd, n_c) + eps\n",
    "    return coarseModelSamples_50000, eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8ce6f",
   "metadata": {},
   "source": [
    "### 3. Define Harrell-Davis weighting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e3b3105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as scp\n",
    "\n",
    "def HarrellDavisWeighting(p, xSorted):\n",
    "    n = xSorted.size\n",
    "    hd = np.empty((2), np.float64)\n",
    "    if n < 2:\n",
    "        hd.flat = np.nan\n",
    "        return hd[0]\n",
    "    v = np.arange(n+1) / float(n)\n",
    "    betacdf = scp.stats.distributions.beta.cdf\n",
    "    _w = betacdf(v, (n+1)*p, (n+1)*(1-p))\n",
    "    w = _w[1:] - _w[:-1]\n",
    "    hd_mean = np.dot(w, xSorted)\n",
    "    hd[0] = hd_mean\n",
    "    hd[1] = np.dot(w, (xSorted-hd_mean)**2)\n",
    "    return hd[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a115419",
   "metadata": {},
   "source": [
    "### 4. Define Quantile Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "94877ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, mstats\n",
    "import pandas as pd\n",
    "\n",
    "def CalcQuantileEstimates(p, p_f, p_c, mu, sd, fineSamples, coarseSamples_lvl1, coarseSamples_lvl2, eps2, numStdMCSamples):\n",
    "    # Compute HD estimators\n",
    "    hdEstimatorFineModel = mstats.hdquantiles(data=fineSamples, prob=(p_f), var=False).item()\n",
    "    hdEstimatorCoarseModel_lvl1 = mstats.hdquantiles(data=coarseSamples_lvl1, prob=(p_f), var=False).item()\n",
    "    hdEstimatorCoarseModel_lvl2 = mstats.hdquantiles(data=coarseSamples_lvl2, prob=(p_c), var=False).item()\n",
    "\n",
    "    # Compute order statistics\n",
    "    fineModelOrderStats = np.sort(fineSamples)\n",
    "    coarseModelOrderStats_lvl1 = np.sort(coarseSamples_lvl1)\n",
    "    coarseModelOrderStats_lvl2 = np.sort(coarseSamples_lvl2)\n",
    "\n",
    "    # MLMC estimators\n",
    "    #mlmcEstimator = hdEstimatorFineModel - hdEstimatorCoarseModel_lvl1 + hdEstimatorCoarseModel_lvl2\n",
    "    mlmcEstimator = (HarrellDavisWeighting(p_f,fineModelOrderStats)\n",
    "                     - HarrellDavisWeighting(p_f,coarseModelOrderStats_lvl1)\n",
    "                     + HarrellDavisWeighting(p_c, coarseModelOrderStats_lvl2)\n",
    "    )\n",
    "\n",
    "    diffsOfOrderStats = np.sort(fineSamples) - np.sort(coarseSamples_lvl1)\n",
    "    #mlmcEstimatorComb = (mstats.hdquantiles(data=diffs, prob=(p_f), var=False).item()\n",
    "    #                     + mstats.hdquantiles(data=coarseSamples_lvl2, prob=(p_c), var=False).item()\n",
    "    #)\n",
    "    mlmcEstimatorComb = (HarrellDavisWeighting(p_f, diffsOfOrderStats)\n",
    "                         + mstats.hdquantiles(data=coarseSamples_lvl2,\n",
    "                                              prob=(p_c),\n",
    "                                              var=False).item()\n",
    "    )\n",
    "\n",
    "    diffs = fineSamples - coarseSamples_lvl1\n",
    "    orderStatsOfDiffs = np.sort(diffs)\n",
    "    mlmcEstimatorApprox = (HarrellDavisWeighting(p_f, orderStatsOfDiffs)\n",
    "                           + mstats.hdquantiles(data=coarseSamples_lvl2, prob=(p_c), var=False).item()\n",
    "    )\n",
    "\n",
    "    # Standard MC estimator\n",
    "    fineModelSamples_stdMC = coarseSamples_lvl2[0:numStdMCSamples-1] - eps2[0:numStdMCSamples-1]\n",
    "    hdEstimatorStandardMC = mstats.hdquantiles(data=fineModelSamples_stdMC,\n",
    "                                               prob=(p),\n",
    "                                               var=False).item()\n",
    "\n",
    "    # Actual quantile\n",
    "    actualQuantile = norm.ppf(p, loc=mu, scale=sd)\n",
    "\n",
    "    # Combine into a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Value\": [\n",
    "            hdEstimatorFineModel,\n",
    "            hdEstimatorCoarseModel_lvl1,\n",
    "            hdEstimatorCoarseModel_lvl2,\n",
    "            mlmcEstimator,\n",
    "            mlmcEstimatorComb,\n",
    "            mlmcEstimatorApprox,\n",
    "            hdEstimatorStandardMC,\n",
    "            actualQuantile\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857c241",
   "metadata": {},
   "source": [
    "### 5. Apply bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b7a0195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    f\"Fine Model HD, {n_f} samples\",\n",
    "    f\"Coarse Model HD, {n_f} samples\",\n",
    "    f\"Coarse Model HD, {n_c} samples\",\n",
    "    \"MLMC (separate terms)\",\n",
    "    \"MLMC (diff. of order stats)\",\n",
    "    \"MLMC (order stats of diff.)\",\n",
    "    f\"Standard MC-HD, {n_std_mc} samples\",\n",
    "    \"Actual Quantile\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({\"Estimator\": estimators})\n",
    "\n",
    "cols = []\n",
    "\n",
    "for i in range(1, n_bootstrap + 1):\n",
    "\n",
    "    fineModelSamples, coarseModelSamples_lvl1, eps1 = SampleLevel1(mu, sd, n_f)\n",
    "    coarseModelSamples_lvl2, eps2 = SampleLevel2(mu, sd, n_c)\n",
    "\n",
    "    col = CalcQuantileEstimates(\n",
    "        p=p, p_f=p, p_c=p, mu=mu, sd=sd,\n",
    "        fineSamples=fineModelSamples,\n",
    "        coarseSamples_lvl1=coarseModelSamples_lvl1,\n",
    "        coarseSamples_lvl2=coarseModelSamples_lvl2,\n",
    "        eps2=eps2,\n",
    "        numStdMCSamples=n_std_mc\n",
    "    )[\"Value\"]\n",
    "\n",
    "    col.name = f\"Run_{i}\"\n",
    "    cols.append(col)\n",
    "\n",
    "new_cols = pd.concat(cols, axis=1)\n",
    "df = pd.concat([df, new_cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3b83a",
   "metadata": {},
   "source": [
    "### 6. Compute bootstrapped statistics for the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f164dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Estimator     Mean  AbsDev     StdDev       RMSE\n",
      "0       Fine Model HD, 50 samples -448.201  76.965  9.164e+01  1.196e+02\n",
      "1     Coarse Model HD, 50 samples -452.978  72.188  9.193e+01  1.168e+02\n",
      "2  Coarse Model HD, 50000 samples -531.193   6.027  4.314e+00  7.411e+00\n",
      "3           MLMC (separate terms) -526.416   1.251  2.636e+01  2.638e+01\n",
      "4     MLMC (diff. of order stats) -526.416   1.251  2.636e+01  2.638e+01\n",
      "5     MLMC (order stats of diff.) -597.578  72.412  1.411e+01  7.377e+01\n",
      "6     Standard MC-HD, 300 samples -536.891  11.726  5.409e+01  5.532e+01\n",
      "7                 Actual Quantile -525.166   0.000  2.275e-13  8.640e-12\n"
     ]
    }
   ],
   "source": [
    "# Compute average across all Run columns\n",
    "run_cols = [f\"Run_{i}\" for i in range(1, n_bootstrap+1)]\n",
    "df[\"Mean\"] = df[run_cols].mean(axis=1)\n",
    "\n",
    "# Extract the Actual Quantile value from the DataFrame\n",
    "actual_value = df.loc[df[\"Estimator\"] == \"Actual Quantile\", \"Mean\"].values[0]\n",
    "\n",
    "# Compute the deviation of the mean from the actual quantile\n",
    "df[\"AbsDev\"] = abs(df[\"Mean\"] - actual_value)\n",
    "\n",
    "# Compute standard deviation across all Run columns\n",
    "df[\"StdDev\"] = df[run_cols].std(axis=1)\n",
    "\n",
    "# Identify all Run columns\n",
    "run_cols = [col for col in df.columns if col.startswith(\"Run_\")]\n",
    "\n",
    "# Compute RMSE (RMS deviation from Actual Quantile)\n",
    "df[\"RMSE\"] = ((df[run_cols] - actual_value) ** 2).mean(axis=1) ** 0.5\n",
    "\n",
    "# Show relevant columns\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "print(df[[\"Estimator\", \"Mean\", \"AbsDev\", \"StdDev\", \"RMSE\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b03c59",
   "metadata": {},
   "source": [
    "### Notations\n",
    "\n",
    "- \"MLMC (separate terms)\" refers to the estimator\n",
    "\n",
    "    $\\sum_{i=1}^{n_{\\text{f}}}{W_{i}^{n_{\\text{f}}}X_{(i)}^{\\text{f}}} - \\sum_{i=1}^{n_{\\text{f}}}{W_{i}^{n_{\\text{f}}}X_{(i)}^{\\text{c}}} + \\sum_{i=1}^{n_{\\text{c}}}{W_{i}^{n_{\\text{c}}}X_{(i)}^{\\text{c}}}$\n",
    "\n",
    "- \"MLMC (diff. of order stats)\" refers to the estimator\n",
    "\n",
    "    $\\sum_{i=1}^{n_{\\text{f}}}{W_{i}^{n_{\\text{f}}}(X_{(i)}^{\\text{f}} - X_{(i)}^{\\text{c}})} + \\sum_{i=1}^{n_{\\text{c}}}{W_{i}^{n_{\\text{c}}}X_{(i)}^{\\text{c}}}$\n",
    "\n",
    "- \"MLMC (order stats of diff.)\" refers to the estimator\n",
    "\n",
    "    $\\sum_{i=1}^{n_{\\text{f}}}{W_{i}^{n_{\\text{f}}}(X^{\\text{f}} - X^{\\text{c}})_{(i)}} + \\sum_{i=1}^{n_{\\text{c}}}{W_{i}^{n_{\\text{c}}}X_{(i)}^{\\text{c}}}$\n",
    "\n",
    "### Observations\n",
    "\n",
    "- Since the Harrell-Davis weights do not depend on the distribution but only on $p$ and $n$, \"MLMC (separate terms)\" and \"MLMC (diff. of order stats)\" yield the same result.\n",
    "\n",
    "- If the difference between the costs $c_{\\text{f}}$ and $c_{\\text{c}}$ is large, \"MLMC (diff. of order stats)\" can yield significantly better results compared to standard HD Monte Carlo.\n",
    "\n",
    "- For $c_{\\text{c}} = \\frac{c_{\\text{f}}}{20}$, \"MLMC (diff. of order stats)\" and standard HD Monte Carlo yield similar results.\n",
    "\n",
    "- If monotonicity between the fina and coarse model is introduced (i.e. the $\\epsilon$ added to the fine model is always non-negative), the results of all MLMC estimators improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae56d4",
   "metadata": {},
   "source": [
    "### Idea\n",
    "\n",
    "The general approach is: \n",
    "\n",
    "\\begin{align*} F^{-1}_{X^{\\text{f}}}(p) &\\approx \\mathbb{E}[X^{\\text{f}}_{((n+1)p)}] \\\\ &= \\mathbb{E}[X^{\\text{f}}_{(k)}] \\\\ &= \\mathbb{E}[X^{\\text{f}}_{(k)}] - \\mathbb{E}[X^{\\text{c}}_{(k)}] + \\mathbb{E}[X^{\\text{c}}_{(k)}] \\\\ &= \\mathbb{E}[X^{\\text{f}}_{((n_{\\text{f}}+1)p_{\\text{f}})}] - \\mathbb{E}[X^{\\text{c}}_{((n_{\\text{f}}+1)p_{\\text{f}})}] + \\mathbb{E}[X^{\\text{c}}_{((n_{\\text{c}}+1)p_{\\text{c}})}] \\\\ &= \\dots \\end{align*}\n",
    "\n",
    "This uses:\n",
    "1. $\\mathbb{E}[X^{\\text{f}}_{((n+1)p)}] \\rightarrow F^{-1}_{X^{\\text{f}}}(p)$ for $n \\rightarrow \\infty$, i.e. $n$ should be chosen large enough to approximate the quantile.\n",
    "\n",
    "2. Define $k \\coloneqq (n+1)p$.\n",
    "\n",
    "3. Add zero.\n",
    "\n",
    "4. Choose $n_{\\text{f}}$ and $n_{\\text{c}}$. Then set $p_{\\text{f}} \\coloneqq \\frac{k}{n_{\\text{f}}+1}$ and $p_{\\text{c}} \\coloneqq \\frac{k}{n_{\\text{c}}+1}$.\n",
    "\n",
    "5. Derive HD-like estimator by:\n",
    "    - \"MLMC (separate terms)\": applying Harrell-Davis to each summand separately\n",
    "\n",
    "    - \"MLMC (diff. of order stats)\": applying Harrell-Davis to each summand separately, then using that the first two terms share the same HD weights.\n",
    "\n",
    "    - \"MLMC (order stats of diff.)\": defining $Z \\coloneqq X^{\\text{f}} - X^{\\text{c}}$ and using that \n",
    "    \n",
    "        \\begin{align*} \\mathbb{E}[X^{\\text{f}}_{((n_{\\text{f}}+1)p_{\\text{f}})}] - \\mathbb{E}[X^{\\text{c}}_{((n_{\\text{f}}+1)p_{\\text{f}})}] + \\mathbb{E}[X^{\\text{c}}_{((n_{\\text{c}}+1)p_{\\text{f}})}] &= \\mathbb{E}[X^{\\text{f}}_{((n_{\\text{f}}+1)p_{\\text{f}})} - X^{\\text{c}}_{((n_{\\text{f}}+1)p_{\\text{f}})}] + \\mathbb{E}[X^{\\text{c}}_{((n_{\\text{c}}+1)p_{\\text{c}})}] \\\\ &= \\mathbb{E}[(X^{\\text{f}} - X^{\\text{c}})_{((n_{\\text{f}}+1)p_{\\text{f}})}] + \\mathbb{E}[X^{\\text{c}}_{((n_{\\text{c}}+1)p_{\\text{c}})}] + \\text{error} \\\\ &= \\mathbb{E}[Z_{((n_{\\text{f}}+1)p_{\\text{f}})}] + \\mathbb{E}[X^{\\text{c}}_{((n_{\\text{c}}+1)p_{\\text{c}})}] + \\text{error} \\end{align*},\n",
    "        \n",
    "        then applying Harrell-Davis to the two summands separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81383b0c",
   "metadata": {},
   "source": [
    "### New Approach: Estimate different quantiles on the two levels ($p_{\\text{f}}$, $p_{\\text{c}}$ instead of $p$)\n",
    "\n",
    "### 1. Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9edf552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of interest: \n",
    "mu = -10\n",
    "sd = 200\n",
    "\n",
    "# Quantile of interest:\n",
    "p = 0.005\n",
    "\n",
    "# Model valuation costs:\n",
    "c_f = 1\n",
    "c_c = c_f / 200\n",
    "\n",
    "# Number of samples:\n",
    "n_std_mc = 260\n",
    "n_f = 50\n",
    "n_c = int(((n_std_mc - n_f) * c_f - n_f * c_c) / c_c)\n",
    "\n",
    "# Quantiles to be estimated on the 2 levels\n",
    "k = (n_std_mc + 1) * p\n",
    "p_f = k / (n_f + 1)\n",
    "p_c = k / (n_c + 1)\n",
    "# Make sure p_f and p_c are in [0,1]\n",
    "\n",
    "# Number of bootstrap samples:\n",
    "n_bootstrap = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fe932b",
   "metadata": {},
   "source": [
    "### 2. Apply bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d243f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    f\"Fine Model HD, {n_f} samples\",\n",
    "    f\"Coarse Model HD, {n_f} samples\",\n",
    "    f\"Coarse Model HD, {n_c} samples\",\n",
    "    \"MLMC (separate terms)\",\n",
    "    \"MLMC (diff. of order stats)\",\n",
    "    \"MLMC (order stats of diff.)\",\n",
    "    f\"Standard MC-HD, {n_std_mc} samples\",\n",
    "    \"Actual Quantile\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({\"Estimator\": estimators})\n",
    "\n",
    "cols = []\n",
    "\n",
    "for i in range(1, n_bootstrap + 1):\n",
    "\n",
    "    fineModelSamples, coarseModelSamples_lvl1, eps1 = SampleLevel1(mu, sd, n_f)\n",
    "    coarseModelSamples_lvl2, eps2 = SampleLevel2(mu, sd, n_c)\n",
    "\n",
    "    col = CalcQuantileEstimates(\n",
    "        p=p, p_f=p_f, p_c=p_c, mu=mu, sd=sd,\n",
    "        fineSamples=fineModelSamples,\n",
    "        coarseSamples_lvl1=coarseModelSamples_lvl1,\n",
    "        coarseSamples_lvl2=coarseModelSamples_lvl2,\n",
    "        eps2=eps2,\n",
    "        numStdMCSamples=n_std_mc\n",
    "    )[\"Value\"]\n",
    "\n",
    "    col.name = f\"Run_{i}\"\n",
    "    cols.append(col)\n",
    "\n",
    "new_cols = pd.concat(cols, axis=1)\n",
    "df = pd.concat([df, new_cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a7c99",
   "metadata": {},
   "source": [
    "### 3. Compute bootstrapped statistics for the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6c625d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Estimator     Mean   AbsDev     StdDev       RMSE\n",
      "0       Fine Model HD, 50 samples -405.712  119.453  6.844e+01  1.377e+02\n",
      "1     Coarse Model HD, 50 samples -410.247  114.918  6.984e+01  1.345e+02\n",
      "2  Coarse Model HD, 41950 samples -827.923  302.757  4.233e+01  3.057e+02\n",
      "3           MLMC (separate terms) -823.388  298.222  4.570e+01  3.017e+02\n",
      "4     MLMC (diff. of order stats) -823.388  298.222  4.570e+01  3.017e+02\n",
      "5     MLMC (order stats of diff.) -887.951  362.785  4.375e+01  3.654e+02\n",
      "6     Standard MC-HD, 260 samples -535.408   10.242  5.842e+01  5.928e+01\n",
      "7                 Actual Quantile -525.166    0.000  2.275e-13  8.640e-12\n"
     ]
    }
   ],
   "source": [
    "# Compute average across all Run columns\n",
    "run_cols = [f\"Run_{i}\" for i in range(1, n_bootstrap+1)]\n",
    "df[\"Mean\"] = df[run_cols].mean(axis=1)\n",
    "\n",
    "# Extract the Actual Quantile value from the DataFrame\n",
    "actual_value = df.loc[df[\"Estimator\"] == \"Actual Quantile\", \"Mean\"].values[0]\n",
    "\n",
    "# Compute the deviation of the mean from the actual quantile\n",
    "df[\"AbsDev\"] = abs(df[\"Mean\"] - actual_value)\n",
    "\n",
    "# Compute standard deviation across all Run columns\n",
    "df[\"StdDev\"] = df[run_cols].std(axis=1)\n",
    "\n",
    "# Identify all Run columns\n",
    "run_cols = [col for col in df.columns if col.startswith(\"Run_\")]\n",
    "\n",
    "# Compute RMSE (RMS deviation from Actual Quantile)\n",
    "df[\"RMSE\"] = ((df[run_cols] - actual_value) ** 2).mean(axis=1) ** 0.5\n",
    "\n",
    "# Show relevant columns\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "print(df[[\"Estimator\", \"Mean\", \"AbsDev\", \"StdDev\", \"RMSE\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
